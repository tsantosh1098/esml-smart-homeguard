{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f3db2e-7c24-4fe6-96e2-c4248b9827c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446d09ec-34ad-46b5-b631-3cf1c450d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"first_100_epochs/model_epoch_100.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271a4ba0-bc8e-4dca-86dd-17b84039bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e868ce3-2645-4c79-80bd-c05ad5374b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file: first_100_epochs/model_epoch_100.h5\n",
      "Extracting model parameters to parameter dictionary ...\n",
      "('model_weights', <HDF5 group \"/model_weights\" (23 members)>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_layers)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# each layer has a group\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer, group \u001b[38;5;129;01min\u001b[39;00m model_layers:\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# in the group the keys are the members: either the layer bias and/or parameters\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p_name \u001b[38;5;129;01min\u001b[39;00m group\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     26\u001b[0m         param \u001b[38;5;241m=\u001b[39m group[p_name]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if len(f.attrs.items()):\n",
    "        print(\"Parameter file: {}\".format(path))\n",
    "        print(\"Extracting model parameters to parameter dictionary ...\")\n",
    "        \n",
    "except ValueError as ve:\n",
    "    print(ve)\n",
    "          \n",
    "if len(f.items())==0:\n",
    "    raise ValueError('No Layers with paramters found')\n",
    "else:\n",
    "    weights = {}\n",
    "        \n",
    "    # each layer has a group\n",
    "    for pp in f.items():\n",
    "        model_layers = pp\n",
    "        break\n",
    "        \n",
    "        \n",
    "    print(model_layers)\n",
    "    # each layer has a group\n",
    "    for layer, group in model_layers:\n",
    "\n",
    "        # in the group the keys are the members: either the layer bias and/or parameters\n",
    "        for p_name in group.keys():\n",
    "            param = group[p_name]\n",
    "            print(p_name, param)\n",
    "\n",
    "            # if the group has 0 members then the layer has no biases or parameters\n",
    "            if len(param) == 0:\n",
    "                weights[layer, None] = None\n",
    "\n",
    "            else:\n",
    "                # for each parameter in the layer output to dictionary\n",
    "                for k_name in param.keys():\n",
    "                    print(p_name, param)\n",
    "                    weights[layer, k_name] = param[k_name][()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "447ff360-fde5-4789-bd50-f44c4e958690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add <HDF5 group \"/model_weights/add\" (0 members)>\n",
      "add_1 <HDF5 group \"/model_weights/add_1\" (0 members)>\n",
      "add_2 <HDF5 group \"/model_weights/add_2\" (0 members)>\n",
      "add_3 <HDF5 group \"/model_weights/add_3\" (0 members)>\n",
      "batch_normalization <HDF5 group \"/model_weights/batch_normalization\" (1 members)>\n",
      "conv2_plus1d <HDF5 group \"/model_weights/conv2_plus1d\" (2 members)>\n",
      "dense_3 <HDF5 group \"/model_weights/dense_3\" (1 members)>\n",
      "flatten <HDF5 group \"/model_weights/flatten\" (0 members)>\n",
      "global_average_pooling3d <HDF5 group \"/model_weights/global_average_pooling3d\" (0 members)>\n",
      "input_2 <HDF5 group \"/model_weights/input_2\" (0 members)>\n",
      "project <HDF5 group \"/model_weights/project\" (2 members)>\n",
      "project_1 <HDF5 group \"/model_weights/project_1\" (2 members)>\n",
      "project_2 <HDF5 group \"/model_weights/project_2\" (2 members)>\n",
      "re_lu <HDF5 group \"/model_weights/re_lu\" (0 members)>\n",
      "residual_main <HDF5 group \"/model_weights/residual_main\" (6 members)>\n",
      "residual_main_1 <HDF5 group \"/model_weights/residual_main_1\" (6 members)>\n",
      "residual_main_2 <HDF5 group \"/model_weights/residual_main_2\" (6 members)>\n",
      "residual_main_3 <HDF5 group \"/model_weights/residual_main_3\" (6 members)>\n",
      "resize_video <HDF5 group \"/model_weights/resize_video\" (0 members)>\n",
      "resize_video_1 <HDF5 group \"/model_weights/resize_video_1\" (0 members)>\n",
      "resize_video_2 <HDF5 group \"/model_weights/resize_video_2\" (0 members)>\n",
      "resize_video_3 <HDF5 group \"/model_weights/resize_video_3\" (0 members)>\n",
      "top_level_model_weights <HDF5 group \"/model_weights/top_level_model_weights\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "# each layer has a group\n",
    "count = 0\n",
    "for layer, group in f.items():\n",
    "    if count == 1:\n",
    "        break\n",
    "    count += 1\n",
    "    # print(layer, group)\n",
    "    \n",
    "    for l, g in group.items():\n",
    "        print(l, g)\n",
    "        \n",
    "        for p_name in g.keys():\n",
    "            param = g[p_name]\n",
    "            # print(p_name, param)\n",
    "            \n",
    "            # if the group has 0 members then the layer has no biases or parameters\n",
    "            if len(param) == 0:\n",
    "                weights[l, None] = None\n",
    "            else:\n",
    "                # for each parameter in the layer output to dictionary\n",
    "                for k_name in param.keys():\n",
    "                    # print(l, \"###########\", k_name)\n",
    "                    # print(p_name,\"####\", k_name, param[k_name][()])\n",
    "                    weights[l, k_name] = param[k_name][()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fed6e682-55a6-4180-a440-b1f3798789e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Flatten \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras import layers\n",
    "import einops\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "\n",
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding, **kwargs):\n",
    "        \"\"\"\n",
    "          A sequence of convolutional layers that first apply the convolution operation over the\n",
    "          spatial dimensions, and then the temporal dimension. \n",
    "        \"\"\"\n",
    "        super(Conv2Plus1D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.seq = keras.Sequential([  \n",
    "            # Spatial decomposition\n",
    "            layers.Conv3D(filters=self.filters,\n",
    "                          kernel_size=(1, self.kernel_size[1], self.kernel_size[2]),\n",
    "                          padding=self.padding),\n",
    "            # Temporal decomposition\n",
    "            layers.Conv3D(filters=self.filters, \n",
    "                          kernel_size=(self.kernel_size[0], 1, 1),\n",
    "                          padding=self.padding)\n",
    "            ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "            \"padding\": self.padding,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class ResidualMain(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Residual block of the model with convolution, layer normalization, and the\n",
    "    activation function, ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.seq = keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, \n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"filters\": self.filters,\n",
    "            \"kernel_size\": self.kernel_size,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class Project(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Project certain dimensions of the tensor as the data is passed through different \n",
    "    sized filters and downsampled. \n",
    "    \"\"\"\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Project, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.seq = keras.Sequential([\n",
    "            layers.Dense(self.units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"units\": self.units,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "    \"\"\"\n",
    "    Add residual blocks to the model. If the last dimensions of the input data\n",
    "    and filter size does not match, project it such that last dimension matches.\n",
    "    \"\"\"\n",
    "    out = ResidualMain(filters, \n",
    "                     kernel_size)(input)\n",
    "\n",
    "    res = input\n",
    "    # Using the Keras functional APIs, project the last dimension of the tensor to\n",
    "    # match the new filter size\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "\n",
    "    return layers.add([res, out])\n",
    "\n",
    "\n",
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width, **kwargs):\n",
    "        super(ResizeVideo, self).__init__(**kwargs)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def call(self, video):\n",
    "        \"\"\"\n",
    "          Use the einops library to resize the tensor.  \n",
    "\n",
    "          Args:\n",
    "            video: Tensor representation of the video, in the form of a set of frames.\n",
    "\n",
    "          Return:\n",
    "            A downsampled size of the video according to the new height and width it should be resized to.\n",
    "        \"\"\"\n",
    "        # b stands for batch size, t stands for time, h stands for height, \n",
    "        # w stands for width, and c stands for the number of channels.\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        resizing_layer = keras.layers.Resizing(self.height, self.width)\n",
    "        images = resizing_layer(images)\n",
    "        videos = einops.rearrange(\n",
    "            images, '(b t) h w c -> b t h w c',\n",
    "            t = old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"height\": self.height,\n",
    "            \"width\": self.width,\n",
    "            \"resizing_layer\": self.resizing_layer,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "input_shape = (None, 30, 224, 224, 3)\n",
    "HEIGHT = input_shape[2]\n",
    "WIDTH = input_shape[3]\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "input = layers.Input(shape=(input_shape[1:]))\n",
    "x = input\n",
    "\n",
    "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n",
    "\n",
    "# Block 1\n",
    "x = add_residual_block(x, 16, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n",
    "\n",
    "# Block 2\n",
    "x = add_residual_block(x, 32, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n",
    "\n",
    "# Block 3\n",
    "x = add_residual_block(x, 64, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n",
    "\n",
    "# Block 4\n",
    "x = add_residual_block(x, 128, (3, 3, 3))\n",
    "\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(NUM_CLASSES)(x)\n",
    "\n",
    "model = keras.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aceb9fc4-eedd-41a1-86b9-3838f27aa9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 30, 224, 22  0           []                               \n",
      "                                4, 3)]                                                            \n",
      "                                                                                                  \n",
      " conv2_plus1d_9 (Conv2Plus1D)   (None, 30, 224, 224  3152        ['input_2[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 30, 224, 224  64         ['conv2_plus1d_9[0][0]']         \n",
      " rmalization)                   , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 30, 224, 224  0           ['batch_normalization_1[0][0]']  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " resize_video_4 (ResizeVideo)   (None, 30, 112, 112  0           ['re_lu_5[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " residual_main_4 (ResidualMain)  (None, 30, 112, 112  6272       ['resize_video_4[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 30, 112, 112  0           ['resize_video_4[0][0]',         \n",
      "                                , 16)                             'residual_main_4[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_5 (ResizeVideo)   (None, 30, 56, 56,   0           ['add_4[0][0]']                  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " project_3 (Project)            (None, 30, 56, 56,   608         ['resize_video_5[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " residual_main_5 (ResidualMain)  (None, 30, 56, 56,   20224      ['resize_video_5[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 30, 56, 56,   0           ['project_3[0][0]',              \n",
      "                                32)                               'residual_main_5[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_6 (ResizeVideo)   (None, 30, 28, 28,   0           ['add_5[0][0]']                  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " project_4 (Project)            (None, 30, 28, 28,   2240        ['resize_video_6[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " residual_main_6 (ResidualMain)  (None, 30, 28, 28,   80384      ['resize_video_6[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 30, 28, 28,   0           ['project_4[0][0]',              \n",
      "                                64)                               'residual_main_6[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_7 (ResizeVideo)   (None, 30, 14, 14,   0           ['add_6[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " project_5 (Project)            (None, 30, 14, 14,   8576        ['resize_video_7[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " residual_main_7 (ResidualMain)  (None, 30, 14, 14,   320512     ['resize_video_7[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 30, 14, 14,   0           ['project_5[0][0]',              \n",
      "                                128)                              'residual_main_7[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling3d_1 (Gl  (None, 128)         0           ['add_7[0][0]']                  \n",
      " obalAveragePooling3D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 128)          0           ['global_average_pooling3d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 9)            1161        ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 443,193\n",
      "Trainable params: 443,161\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf114bc7-e4f3-491d-b27f-3bcb40b7e94f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[1;32m      3\u001b[0m               optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38d1bb-4bbc-47ca-8d85-f02154f1d0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84c236f9-d341-43c5-b637-863d621a86d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: ('batch_normalization', 'beta:0'). Existing layers are: ['input_2', 'conv2_plus1d_9', 'batch_normalization_1', 're_lu_5', 'resize_video_4', 'residual_main_4', 'add_4', 'resize_video_5', 'project_3', 'residual_main_5', 'add_5', 'resize_video_6', 'project_4', 'residual_main_6', 'add_6', 'resize_video_7', 'project_5', 'residual_main_7', 'add_7', 'global_average_pooling3d_1', 'flatten_1', 'dense_6'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Iterate through layers and set the weights\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name, layer_weights \u001b[38;5;129;01min\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         layer\u001b[38;5;241m.\u001b[39mset_weights(layer_weights)\n",
      "File \u001b[0;32m/usr/local/python-env/py39/lib/python3.9/site-packages/keras/engine/training.py:2922\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m   2921\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[0;32m-> 2922\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2923\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2924\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2925\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`get_layer`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: ('batch_normalization', 'beta:0'). Existing layers are: ['input_2', 'conv2_plus1d_9', 'batch_normalization_1', 're_lu_5', 'resize_video_4', 'residual_main_4', 'add_4', 'resize_video_5', 'project_3', 'residual_main_5', 'add_5', 'resize_video_6', 'project_4', 'residual_main_6', 'add_6', 'resize_video_7', 'project_5', 'residual_main_7', 'add_7', 'global_average_pooling3d_1', 'flatten_1', 'dense_6']."
     ]
    }
   ],
   "source": [
    "# Iterate through layers and set the weights\n",
    "for layer_name, layer_weights in weights.items():\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    if layer is not None:\n",
    "        layer.set_weights(layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8450a62-b1ce-44c5-a72a-c7416cd3dd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('batch_normalization', 'beta:0'), ('batch_normalization', 'gamma:0'), ('batch_normalization', 'moving_mean:0'), ('batch_normalization', 'moving_variance:0'), ('conv2_plus1d', 'bias:0'), ('conv2_plus1d', 'kernel:0'), ('dense_3', 'bias:0'), ('dense_3', 'kernel:0'), ('project', 'bias:0'), ('project', 'kernel:0'), ('project', 'beta:0'), ('project', 'gamma:0'), ('project_1', 'bias:0'), ('project_1', 'kernel:0'), ('project_1', 'beta:0'), ('project_1', 'gamma:0'), ('project_2', 'bias:0'), ('project_2', 'kernel:0'), ('project_2', 'beta:0'), ('project_2', 'gamma:0'), ('residual_main', 'bias:0'), ('residual_main', 'kernel:0'), ('residual_main', 'beta:0'), ('residual_main', 'gamma:0'), ('residual_main_1', 'bias:0'), ('residual_main_1', 'kernel:0'), ('residual_main_1', 'beta:0'), ('residual_main_1', 'gamma:0'), ('residual_main_2', 'bias:0'), ('residual_main_2', 'kernel:0'), ('residual_main_2', 'beta:0'), ('residual_main_2', 'gamma:0'), ('residual_main_3', 'bias:0'), ('residual_main_3', 'kernel:0'), ('residual_main_3', 'beta:0'), ('residual_main_3', 'gamma:0')])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73f5b00b-a013-41dd-a254-a68f09afdf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "conv2_plus1d_9\n",
      "batch_normalization_1\n",
      "re_lu_5\n",
      "resize_video_4\n",
      "residual_main_4\n",
      "add_4\n",
      "resize_video_5\n",
      "project_3\n",
      "residual_main_5\n",
      "add_5\n",
      "resize_video_6\n",
      "project_4\n",
      "residual_main_6\n",
      "add_6\n",
      "resize_video_7\n",
      "project_5\n",
      "residual_main_7\n",
      "add_7\n",
      "global_average_pooling3d_1\n",
      "flatten_1\n",
      "dense_6\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e1456-5922-49c7-a004-73e509afcea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
